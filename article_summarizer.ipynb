{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizing research papers\n",
    "\n",
    "This notebook looks at text summarization and specifically, downloading arXiv papers in PDF format and summarizing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First install the required packages\n",
    "!pip install openai wget pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "import pdfplumber\n",
    "import torch\n",
    "import wget\n",
    "\n",
    "from os.path import exists\n",
    "from transformers import pipeline, logging\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Supress some unnecessary warnings\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a class which will handle PDF file downloading from arXiv and converting the PDF pages to text for us for easy summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF file handler for downlading papers from arXiv\n",
    "class PDFFile:\n",
    "    pages = []\n",
    "\n",
    "    def __init__(self, url: str, file_name: str):\n",
    "        # Validate URL\n",
    "        if \"arxiv.org\" not in url:\n",
    "            raise Exception(f\"The URL is not for arxiv.org: {url}\")\n",
    "        # Is this a URL to the paper or to the PDF?\n",
    "        r = urlparse(url)\n",
    "        if \"/abs/\" in url:\n",
    "            # URL to the paper - not the PDF. Create PDF url\n",
    "            url = url.replace('/abs/', '/pdf/')\n",
    "        elif r.path.endswith('pdf') or \"/pdf/\" in url:\n",
    "            # This is a URL to the PDf\n",
    "            pass\n",
    "        else:\n",
    "            raise Exception(f\"The URL is not for a paper nor PDF: {url}\")\n",
    "        self.url = url\n",
    "        self.file_name = file_name\n",
    "        if not exists(file_name):\n",
    "            print(f'Will download: {url}')\n",
    "            self.get_file()\n",
    "        else:\n",
    "            self.path = file_name\n",
    "        self.get_pages()\n",
    "\n",
    "    def get_file(self):\n",
    "        # Get file\n",
    "        file = wget.download(self.url, self.file_name)\n",
    "        self.path = pathlib.Path(file)\n",
    "\n",
    "    def get_pages(self):\n",
    "        # Get pages from PDF file\n",
    "        pgs = pdfplumber.open(self.path).pages\n",
    "        # Iterate over all the pages\n",
    "        for p in pgs:\n",
    "            txt = p.extract_text()\n",
    "            self.pages.append(txt)\n",
    "\n",
    "    def page_count(self) -> int:\n",
    "        return len(self.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('mps') if torch.has_mps else torch.device(\"cpu\")\n",
    "non_mps = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# MPS devices currently don't appear to work correctly with this pipeline - so going with non-MPS\n",
    "summarizer = pipeline(\"summarization\", \"pszemraj/long-t5-tglobal-base-16384-book-summary\", device=non_mps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to get a summary for a range of pages from a PDF file\n",
    "def get_summary(pdf: PDFFile, start: int = 0, end: int = -1):\n",
    "\t# If end is -1, we go to the end of the list\n",
    "\tif end == -1:\n",
    "\t\tend = len(pdf.pages)\n",
    "\ttxt = ''\n",
    "\tfor p in pdf.pages[start:end]:\n",
    "\t\ttxt += p + '\\n'\n",
    "\tsumm = summarizer(txt)[0]['summary_text']\n",
    "\treturn summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fahim/miniconda3/envs/ml/lib/python3.9/site-packages/transformers/modeling_utils.py:717: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In this paper, the author demonstrates an efficient and cost-effective method for generating convincing images by using a combination of image-editing methods. He uses a mixture of diffusion-based and text-conditioned modeling approaches to develop a new kind of image editor that can be used to create accurate edits in a wide variety of subject matter.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf = PDFFile('https://arxiv.org/abs/2210.11427', 'diffedit.pdf')\n",
    "results = get_summary(pdf, 0, 8)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above summarizes all 8 pages in one go and what you get is just an overall summary. What if we wanted to see something a bit more detailed for each page? We can pass each page separately to the summrizer and see if a single summary per page make things clearer?\n",
    "\n",
    "Let's modify the `get_summary` method to support summarizing a range of pages or a page at a time ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated Helper method to get a summary for a range of pages from a PDF file - either a page at a time,\n",
    "# or, for a range of pages summarized at once\n",
    "def get_summary(pdf: PDFFile, start: int = 0, end: int = -1, each_page: bool = True):\n",
    "\tresults = ''\n",
    "\t# If end is -1, we go to the end of the list\n",
    "\tif end == -1:\n",
    "\t\tend = len(pdf.pages)\n",
    "\ttxt = ''\n",
    "\tfor p in pdf.pages[start:end]:\n",
    "\t\tif each_page:\n",
    "\t\t\tsumm = summarizer(p)[0]['summary_text']\n",
    "\t\t\tresults += summ + '\\n\\n'\n",
    "\t\telse:\n",
    "\t\t\ttxt += p + '\\n'\n",
    "\tif not each_page:\n",
    "\t\tresults = summarizer(txt)[0]['summary_text']\n",
    "\treturn results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fahim/miniconda3/envs/ml/lib/python3.9/site-packages/transformers/modeling_utils.py:717: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this paper, the author discusses the use of masked image-editing to create convincing images for text. The author uses a combination of mask-based image generation and canbe-viewed images to create realistic, eloquent effects.\n",
      "\n",
      "In this paper, we present a new approach to image-editing. We focus on the use of machine learning to predict where images should be edited and how they should be manipulated. This paper also presents an extended discussion of image-retrieval, which involves using machine learning approaches to learn how to manipulate images in real time.\n",
      "\n",
      "The first part of the paper discusses some of the most important methods for transforming images into text. For example, in the Diffusion-Framework approach, we use a novel method called \"Diffussion-Matrion\" to transform an image into a model that can be used to predict how it will change over time.\n",
      "\n",
      "In this paper, the author demonstrates how to use a noise-reduction technique to decode an image and then apply that information to a text query. The results are used to create a mask which represents what parts of the image should be changed to correspond to the query.\n",
      "\n",
      "In this paper, we demonstrate how to decode an image by using a mask. We use the mask as a guide to decipher the meaning of the words in the image, and then use the transformed image as the input for the decryption. The results are quite similar to those obtained with the original image, although they are slightly different.\n",
      "\n",
      "In this paper, we present three experiments on three different image-representing datasets. The first is a set of images that belong to one class and are to be edited so that they will show an object of the other class as indicated in the query. The second is based on a diffusion model trained upon ImageNet at a resolution of 256x256; the third is compared to the concurrent work of Hertzetal for semantic image-editing. We compare these methods to those used for conventional image-evaluation. For semantic image Editing, we have two contradictories: 1) matchthetextquerie and 2) staying close to theinput image. These contradictions lead us to use tradeoff curves to determine which method is better.\n",
      "\n",
      "In this paper, we demonstrate the use of a new kind of image-mapping technique called \"diffedit\" to reduce the amount of time it takes to mask an image. This new approach allows us to directly compare the results of different image-retrieval methods with that of the previous methods. We compare the performance of the two approaches: Diffedit is able to achieve high-contritional values for both images and text without loss of information; and the newer approach uses masking to hide the actual image.\n",
      "\n",
      "In this paper, the author demonstrates how to use a set of prescripted images to create a table of fruits and a bowl of pears. He then compares the results of these two approaches to determine which approach is best. The first experiment involves using an image as a reference text while the second uses a mask to represent the fruit in question. This gives the author better control over the final product. For example, when the image is presented as if it were a picture, the result is much better than that of the original image.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pdf = PDFFile('https://arxiv.org/abs/2210.11427', 'diffedit.pdf')\n",
    "results = get_summary(pdf, 0, 8)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, that certainly gives us longer text and a better overview of each page, but I'm not sure that there's enough info in there for somebody to be able to understand the paper entirely ðŸ™‚ But it's a start right?\n",
    "\n",
    "The model card for the model used is here:\n",
    "https://huggingface.co/pszemraj/long-t5-tglobal-base-16384-book-summary\n",
    "\n",
    "It might be possible to improve upon the results by using other parameters/options supported by the model and/or trying different text summarization model. But that's an exercise for later perhaps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d269c22252d3933c69cec7635f2be9a6e217552820b81d3d1e9b4e5a7aa8772"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
